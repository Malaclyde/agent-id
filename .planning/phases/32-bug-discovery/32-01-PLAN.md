---
phase: 32-bug-discovery
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/32-bug-discovery/test-results/backend-results.txt
  - .planning/phases/32-bug-discovery/test-results/frontend-results.txt
  - .planning/phases/32-bug-discovery/test-results/e2e-results.txt
autonomous: true

must_haves:
  truths:
    - "Backend vitest suite has been executed and full output captured"
    - "Frontend vitest unit test suite has been executed and full output captured"
    - "E2E Playwright suite has been executed and full output captured"
  artifacts:
    - path: ".planning/phases/32-bug-discovery/test-results/backend-results.txt"
      provides: "Complete backend test output including pass/fail counts and failure details"
    - path: ".planning/phases/32-bug-discovery/test-results/frontend-results.txt"
      provides: "Complete frontend unit test output including pass/fail counts and failure details"
    - path: ".planning/phases/32-bug-discovery/test-results/e2e-results.txt"
      provides: "Complete E2E test output including pass/fail counts and failure details"
  key_links:
    - from: "backend vitest run"
      to: ".planning/phases/32-bug-discovery/test-results/backend-results.txt"
      via: "stdout/stderr capture"
      pattern: "vitest run.*backend"
    - from: "frontend vitest run"
      to: ".planning/phases/32-bug-discovery/test-results/frontend-results.txt"
      via: "stdout/stderr capture"
      pattern: "vitest run.*frontend"
    - from: "playwright test run"
      to: ".planning/phases/32-bug-discovery/test-results/e2e-results.txt"
      via: "stdout/stderr capture"
      pattern: "playwright test"
---

<objective>
Execute all test suites across the full stack and capture complete output for analysis.

Purpose: Satisfy BUGS-01 — run backend, frontend, and E2E test suites to surface all failures. Raw test output is preserved for the analysis plan that follows.
Output: Three result files containing complete test output from each suite.
</objective>

<execution_context>
./.opencode/get-shit-done/workflows/execute-plan.md
./.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/32-bug-discovery/32-CONTEXT.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Execute backend test suite</name>
  <files>.planning/phases/32-bug-discovery/test-results/backend-results.txt</files>
  <action>
    Create the output directory: `mkdir -p .planning/phases/32-bug-discovery/test-results`

    Run the backend vitest suite and capture ALL output (stdout + stderr) to a file.
    The backend uses `@cloudflare/vitest-pool-workers` with `defineWorkersConfig`.

    Command (run from repo root):
    ```bash
    cd backend && npx vitest run --reporter=verbose 2>&1 | tee ../.planning/phases/32-bug-discovery/test-results/backend-results.txt
    ```

    Use `--reporter=verbose` to get individual test names with pass/fail status.
    Use `tee` so output is both visible and saved.
    Do NOT use `--bail` — let ALL tests run even if some fail.

    If vitest exits with non-zero (test failures), that is EXPECTED. Do not treat test failures as task failures. The goal is to capture the output.

    After the run, verify the output file exists and contains test results (look for "Tests" summary line).
  </action>
  <verify>
    - File `.planning/phases/32-bug-discovery/test-results/backend-results.txt` exists
    - File contains vitest output with test counts (pass/fail/skip)
    - File is non-empty and includes individual test names
  </verify>
  <done>Backend test results captured with full verbose output including all pass/fail/skip details</done>
</task>

<task type="auto">
  <name>Task 2: Execute frontend unit test suite</name>
  <files>.planning/phases/32-bug-discovery/test-results/frontend-results.txt</files>
  <action>
    Run the frontend vitest unit test suite and capture ALL output.
    The frontend uses vitest with jsdom environment, config at `frontend/test/unit/vitest.config.ts`.

    Command (run from repo root):
    ```bash
    cd frontend && npx vitest run --config test/unit/vitest.config.ts --reporter=verbose 2>&1 | tee ../.planning/phases/32-bug-discovery/test-results/frontend-results.txt
    ```

    Use `--reporter=verbose` for individual test names.
    Do NOT use `--bail` — let ALL tests run.

    Known context: STATE.md reports 182/196 frontend tests passing (14 failing). Capture all failures with their error messages and stack traces.

    If vitest exits with non-zero, that is EXPECTED. The goal is to capture failures.
  </action>
  <verify>
    - File `.planning/phases/32-bug-discovery/test-results/frontend-results.txt` exists
    - File contains vitest output with test counts
    - File includes failure details with error messages for any failing tests
  </verify>
  <done>Frontend unit test results captured with full verbose output including all pass/fail/skip details</done>
</task>

<task type="auto">
  <name>Task 3: Execute E2E Playwright test suite</name>
  <files>.planning/phases/32-bug-discovery/test-results/e2e-results.txt</files>
  <action>
    Run the E2E Playwright test suite and capture ALL output.
    The E2E config is at `test/e2e/playwright.config.ts` and auto-starts both backend (port 8787) and frontend (port 3000) dev servers.

    **Pre-check:** Before running, verify ports 8787 and 3000 are not already in use:
    ```bash
    lsof -i :8787 -i :3000 2>/dev/null
    ```
    If ports are in use, note this in the output but proceed — the playwright config has `reuseExistingServer: true` for non-CI.

    **Run database migrations first** (E2E tests need the test database):
    ```bash
    npm run db:migrate:test
    ```

    Command (run from repo root):
    ```bash
    npx playwright test -c test/e2e/playwright.config.ts --reporter=list 2>&1 | tee .planning/phases/32-bug-discovery/test-results/e2e-results.txt
    ```

    Use `--reporter=list` for clear per-test output.
    The config runs tests sequentially (fullyParallel: false, workers: 1).
    Tests run across chromium, firefox, and webkit browsers.

    If playwright exits with non-zero, that is EXPECTED. The goal is to capture failures.

    **Timeout consideration:** E2E tests involve real browser automation and server startup. Allow up to 10 minutes for the full suite. If Playwright hangs, capture whatever output exists.
  </action>
  <verify>
    - File `.planning/phases/32-bug-discovery/test-results/e2e-results.txt` exists
    - File contains Playwright output with test counts
    - File includes results from at least one browser project (chromium)
  </verify>
  <done>E2E test results captured with full output including all pass/fail details across browser projects</done>
</task>

</tasks>

<verification>
All three test result files exist in `.planning/phases/32-bug-discovery/test-results/`:
- `backend-results.txt` — contains vitest output with test summary
- `frontend-results.txt` — contains vitest output with test summary
- `e2e-results.txt` — contains Playwright output with test summary

Each file includes individual test names and failure details where applicable.
</verification>

<success_criteria>
- All three test suites have been executed to completion (not aborted early)
- Complete output is captured including failure messages and stack traces
- Result files are ready for analysis in Plan 02
</success_criteria>

<output>
After completion, create `.planning/phases/32-bug-discovery/32-01-SUMMARY.md`
</output>
